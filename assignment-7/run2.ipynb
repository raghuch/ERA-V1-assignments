{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2 import Net\n",
    "from train_test_loop import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f07cab47550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              72\n",
      "              ReLU-2            [-1, 8, 26, 26]               0\n",
      "       BatchNorm2d-3            [-1, 8, 26, 26]              16\n",
      "           Dropout-4            [-1, 8, 26, 26]               0\n",
      "            Conv2d-5           [-1, 16, 24, 24]           1,152\n",
      "              ReLU-6           [-1, 16, 24, 24]               0\n",
      "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
      "           Dropout-8           [-1, 16, 24, 24]               0\n",
      "            Conv2d-9           [-1, 10, 24, 24]             160\n",
      "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
      "           Conv2d-11           [-1, 16, 10, 10]           1,440\n",
      "             ReLU-12           [-1, 16, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
      "          Dropout-14           [-1, 16, 10, 10]               0\n",
      "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
      "             ReLU-16             [-1, 16, 8, 8]               0\n",
      "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
      "          Dropout-18             [-1, 16, 8, 8]               0\n",
      "           Conv2d-19             [-1, 16, 6, 6]           2,304\n",
      "             ReLU-20             [-1, 16, 6, 6]               0\n",
      "      BatchNorm2d-21             [-1, 16, 6, 6]              32\n",
      "          Dropout-22             [-1, 16, 6, 6]               0\n",
      "        AvgPool2d-23             [-1, 16, 1, 1]               0\n",
      "           Conv2d-24             [-1, 10, 1, 1]             160\n",
      "================================================================\n",
      "Total params: 7,736\n",
      "Trainable params: 7,736\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.60\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_train_transforms = transforms.Compose([\n",
    "                                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))]) #None\n",
    "default_test_transforms = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]) #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = get_augmented_MNIST_dataset(\"~/work/data/\", \n",
    "                                    train_tfms=default_train_transforms, test_tfms=default_test_transforms,\n",
    "                                    batch_sz=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "scheduler = get_schedulder(optimizer, \"StepLR\", step_size=6, gamma=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.06363967061042786 Batch_id=468 Accuracy=98.08: 100%|██████████| 469/469 [00:01<00:00, 306.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Running EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.061006009578704834 Batch_id=468 Accuracy=98.41: 100%|██████████| 469/469 [00:01<00:00, 289.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "Running EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.04641694948077202 Batch_id=468 Accuracy=98.63: 100%|██████████| 469/469 [00:01<00:00, 300.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "Running EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.02934526838362217 Batch_id=468 Accuracy=98.68: 100%|██████████| 469/469 [00:01<00:00, 303.89it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Running EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.033484023064374924 Batch_id=468 Accuracy=98.70: 100%|██████████| 469/469 [00:01<00:00, 305.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 9921/10000 (99.21%)\n",
      "\n",
      "Running EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0482063852250576 Batch_id=468 Accuracy=98.79: 100%|██████████| 469/469 [00:01<00:00, 288.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "Running EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.06527023017406464 Batch_id=468 Accuracy=98.79: 100%|██████████| 469/469 [00:01<00:00, 284.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Running EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.03801874443888664 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:01<00:00, 277.89it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 9916/10000 (99.16%)\n",
      "\n",
      "Running EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.01813000626862049 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:01<00:00, 294.30it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 9925/10000 (99.25%)\n",
      "\n",
      "Running EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.005274960771203041 Batch_id=468 Accuracy=98.89: 100%|██████████| 469/469 [00:01<00:00, 296.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Running EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.027188187465071678 Batch_id=468 Accuracy=99.00: 100%|██████████| 469/469 [00:01<00:00, 305.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 9935/10000 (99.35%)\n",
      "\n",
      "Running EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.023167172446846962 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:01<00:00, 304.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Running EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0857502818107605 Batch_id=468 Accuracy=98.98: 100%|██████████| 469/469 [00:01<00:00, 289.18it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 9944/10000 (99.44%)\n",
      "\n",
      "Running EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.012845419347286224 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:01<00:00, 298.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 9916/10000 (99.16%)\n",
      "\n",
      "Running EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.053014159202575684 Batch_id=468 Accuracy=98.98: 100%|██████████| 469/469 [00:01<00:00, 296.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 9944/10000 (99.44%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=15\n",
    "for i in range(EPOCHS):\n",
    "    print(\"Running EPOCH: \"+str(i+1))\n",
    "    train(model, device, train_dataloader, optimizer=optimizer, epoch=i)\n",
    "    test(model, device, test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target: \n",
    "Reduce the model size to less than 8k params (primary), and tweak with lr/scheduler\n",
    "\n",
    "#### Result: \n",
    "Accuracy 99.444 but fluctuating. Model size: 7736"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "\n",
    "Now trying to get the model size down first. The change is in the backbone CNN which goes like this: input block -> 2 conv blocks (conv + ReLU) -> transition block (2x2 maxpool) -> 4 conv blocks (conv + ReLU) -> final conv2d layer. The difference from Step 1 is the number of channels: Step1 has a channel progression like 1 -> 32 -> 64 -> 128 -> 32 -> 64 -> 128 -> 10 -> 10, where as we don't cross 16 channels in any conv2d layer here.  The new channel progression is 1 -> 8 -> 16 -> 10 -> 16 -> 16 -> 10 with a GAP of kernel size 6 before the last layer. CHange the lr scheduler with lr = 0.05, step_size = 6 and gamma = 0.25. The final change is the removal of one conv block just before the GAP layer, as an experiment to reduce model size, and the number of params is 7,736 (within our range). I selected that particular conv block since the number of input and output channels are the same, so I thought I could remove since number of input and output features is the same. (May work for smaller datasets like MNIST, but may fail on larger datasets since many more features are present in larger datasets). The test accuracy for 15 epochs: 99.44% but is fluctuating. While we do achieve the required test accuracy, it is not consistent, so may be we are reducing the lr too fast (_i.e._ we should increase step_size or decrease gamma or increase lr or a combination of these three)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
